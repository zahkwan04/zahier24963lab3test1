LAB3 TEST1 Q2

NAME : MUHAMMAD ZAHIER ZAKWAN BIN MOHD ARBA'AI
ID 24963
PROG: COE
--------------
FIRST TERMINAL
--------------

###############################################################
#                          WARNING!!!!                        #
# This is a sandbox environment. Using personal credentials   #
# is HIGHLY! discouraged. Any consequences of doing so are    #
# completely the user's responsibilites.                      #
#                                                             #
# The PWD team.                                               #
###############################################################
[node1] (local) root@192.168.0.7 ~
$ docker swarm init --advertise-addr $(hostname -i)
Swarm initialized: current node (jx95dadbq8ps54mxe8axdi6ot) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join --token SWMTKN-1-2lqadnxkgaohkqf8r4ezh78ym1fnmrm257h9flq5x57rwfdzsd-2ob6b33lmkws1eo4om2jrxbsu 192.168.0.7:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.

[node1] (local) root@192.168.0.7 ~
$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUSENGINE VERSION
jx95dadbq8ps54mxe8axdi6ot *   node1               Ready               Active              Leader19.03.4
[node1] (local) root@192.168.0.7 ~
$ docker swarm join --token SWMTKN-1-2lqadnxkgaohkqf8r4ezh78ym1fnmrm257h9flq5x57rwfdzsd-2ob6b33lmkws1eo4om2jrxbsu 192.168.0.7:2377
Error response from daemon: This node is already part of a swarm. Use "docker swarm leave" to leave this swarm and join another one.
[node1] (local) root@192.168.0.7 ~
$ docker node ls
ID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUSENGINE VERSION
jx95dadbq8ps54mxe8axdi6ot *   node1               Ready               Active              Leader19.03.4
7f5lbjy963zw1ht0t7jxt56ld     node2               Ready               Active19.03.4
[node1] (local) root@192.168.0.7 ~
$ git clone https://github.com/zayozayo/zahier24963lab3test1.git
Cloning into 'zahier24963lab3test1'...
remote: Enumerating objects: 32, done.
remote: Counting objects: 100% (32/32), done.
remote: Compressing objects: 100% (29/29), done.
remote: Total 32 (delta 3), reused 0 (delta 0), pack-reused 0
Unpacking objects: 100% (32/32), done.
[node1] (local) root@192.168.0.7 ~
$ ls
zahier24963lab3test1
[node1] (local) root@192.168.0.7 ~
$ cd zahier24963lab3test1
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1
$ ls
README.md  test
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1
$ cd test
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$ ls
Q1_ConnectPHP&Rediscache.txt
Q1_Replaced Linkextractor with wikicralwer output.txt
README.md
api
apibkup
docker-compose.yml
docker-composebkup.txt
testlab3ori
www
wwwbkup
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$ docker stack deploy --compose-file=docker-compose.yml wikistack
Ignoring unsupported options: build

Creating network wikistack_default
Creating service wikistack_api
Creating service wikistack_web
Creating service wikistack_redis
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$ docker stack ls
NAME                SERVICES            ORCHESTRATOR
wikistack           3                   Swarm
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$ docker stack services wikistack
ID                  NAME                MODE                REPLICAS            IMAGE PORTS
mv28b44lmtdb        wikistack_api       replicated          0/1                 wikicrawler-api:step5-python *:5000->5000/tcp
owuatcqmyg61        wikistack_redis     replicated          1/1                 redis:latest
wkcx725u4q2d        wikistack_web       replicated          0/1                 wikicrawler-web:step5-python *:80->80/tcp
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$ docker-compose up -d --build
WARNING: The Docker Engine you're using is running in swarm mode.

Compose does not use swarm mode to deploy services to multiple nodes in a swarm. All containers will be scheduled on the current node.

To deploy your application across the swarm, use `docker stack deploy`.

Creating network "test_default" with the default driver
Building web
Step 1/4 : FROM       php:7-apache
7-apache: Pulling from library/php
68ced04f60ab: Pull complete
1d2a5d8fa585: Pull complete
5d59ec4ae241: Pull complete
d42331ef4d44: Pull complete
408b7b7ee112: Pull complete
570cd47896d5: Pull complete
2419413b2a16: Pull complete
2c7832852643: Pull complete
8b0b209a25bc: Pull complete
46011418685f: Pull complete
68be3748ea55: Pull complete
4e3af655ec1e: Pull complete
9f579d3b7159: Pull complete
Digest: sha256:c496c0f962eaaea0f52d9c068bf331fe477703d4657f99b955a2a35a4c3486c4
Status: Downloaded newer image for php:7-apache
 ---> d753d5b380a1
Step 2/4 : LABEL      maintainer="Sawood Alam <@ibnesayeed>"
 ---> Running in 751ca3ee3942
Removing intermediate container 751ca3ee3942
 ---> 9e55b650fe34
Step 3/4 : ENV        API_ENDPOINT="http://localhost:5000/api/"
 ---> Running in d4468f0e86a3
Removing intermediate container d4468f0e86a3
 ---> eee5b08fa536
Step 4/4 : COPY       . /var/www/html/
 ---> 1a78f9bc45e4
Successfully built 1a78f9bc45e4
Successfully tagged wikicrawler-web:step5-python
Building api
Step 1/9 : FROM python:3
3: Pulling from library/python
50e431f79093: Pull complete
dd8c6d374ea5: Pull complete
c85513200d84: Pull complete
55769680e827: Pull complete
f5e195d50b88: Pull complete
94cdd3612287: Pull complete
3b37b69935d4: Pull complete
b9add85f08c4: Pull complete
aa1f4a29beac: Pull complete
Digest: sha256:da4f61227d5facb694293c1356051403d0d163a2d7aa8a0e0d3d9cfc347e3901
Status: Downloaded newer image for python:3
 ---> f88b2f81f83a
Step 2/9 : LABEL maintainer="Zahier <@24963>"
 ---> Running in 8627bf1a50e9
Removing intermediate container 8627bf1a50e9
 ---> 8160e1eef7e3
Step 3/9 : ENV REDIS_URL="redis://localhost:6379"
 ---> Running in 2c17c6889df3
Removing intermediate container 2c17c6889df3
 ---> 4edf877b3a94
Step 4/9 : WORKDIR /app
 ---> Running in d2b53cd9934b
Removing intermediate container d2b53cd9934b
 ---> 349bd34dd50a
Step 5/9 : COPY requirements.txt /app/
 ---> d196c6cc9ea0
Step 6/9 : RUN pip install -r requirements.txt
 ---> Running in 6c1ef8d6802b
Collecting beautifulsoup4
  Downloading beautifulsoup4-4.8.2-py3-none-any.whl (106 kB)
Collecting flask
  Downloading Flask-1.1.1-py2.py3-none-any.whl (94 kB)
Collecting redis
  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)
Collecting wikipedia
  Downloading wikipedia-1.4.0.tar.gz (27 kB)
Collecting requests
  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)
Collecting soupsieve>=1.2
  Downloading soupsieve-2.0-py2.py3-none-any.whl (32 kB)
Collecting Werkzeug>=0.15
  Downloading Werkzeug-1.0.0-py2.py3-none-any.whl (298 kB)
Collecting itsdangerous>=0.24
  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)
Collecting Jinja2>=2.10.1
  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)
Collecting click>=5.1
  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)
Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1
  Downloading urllib3-1.25.8-py2.py3-none-any.whl (125 kB)
Collecting idna<3,>=2.5
  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)
Collecting chardet<4,>=3.0.2
  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)
Collecting MarkupSafe>=0.23
  Downloading MarkupSafe-1.1.1-cp38-cp38-manylinux1_x86_64.whl (32 kB)
Building wheels for collected packages: wikipedia
  Building wheel for wikipedia (setup.py): started
  Building wheel for wikipedia (setup.py): finished with status 'done'
  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11685 sha256=69944e4d0a1d957159bf3421d81f0174553b7d75b4a2967aa9d83874e5bacc33
  Stored in directory: /root/.cache/pip/wheels/07/93/05/72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a
Successfully built wikipedia
Installing collected packages: soupsieve, beautifulsoup4, Werkzeug, itsdangerous, MarkupSafe, Jinja2, click, flask, redis, urllib3, idna, chardet, certifi, requests, wikipedia
Successfully installed Jinja2-2.11.1 MarkupSafe-1.1.1 Werkzeug-1.0.0 beautifulsoup4-4.8.2 certifi-2019.11.28 chardet-3.0.4 click-7.0 flask-1.1.1 idna-2.9 itsdangerous-1.1.0 redis-3.4.1 requests-2.23.0 soupsieve-2.0 urllib3-1.25.8 wikipedia-1.4.0
Removing intermediate container 6c1ef8d6802b
 ---> 6cfb4ab459d9
Step 7/9 : COPY *.py /app/
 ---> c06940538838
Step 8/9 : RUN chmod a+x *.py
 ---> Running in 2a13797284f8
Removing intermediate container 2a13797284f8
 ---> e454acb923f3
Step 9/9 : CMD ["./main.py"]
 ---> Running in 015801ba86d3
Removing intermediate container 015801ba86d3
 ---> cbea964fbdf8
Successfully built cbea964fbdf8
Successfully tagged wikicrawler-api:step5-python
Pulling redis (redis:)...
latest: Pulling from library/redis
68ced04f60ab: Already exists
7ecc253967df: Pull complete
765957bf98d4: Pull complete
52f16772e1ca: Pull complete
2e43ba99c3f3: Pull complete
d95576c71392: Pull complete
Creating test_api_1 ...
Creating test_web_1   ... error
Creating test_redis_1 ...

Creating test_api_1   ... doneest_web_1 (1dcb62168ff606bf3d2a5467f4eb4e2f106b9aa1234e8e6d8918f2652916dc9d): Error starting userland proxy: lCreating test_redis_1 ... done

ERROR: for web  Cannot start service web: driver failed programming external connectivity on endpoint test_web_1 (1dcb62168ff606bf3d2a5467f4eb4e2f106b9aa1234e8e6d8918f2652916dc9d): Error starting userland proxy: listen tcp 0.0.0.0:80: bind: address already in use
ERROR: Encountered errors while bringing up the project.
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$ docker service scale wikistack_api=5
wikistack_api scaled to 5
overall progress: 5 out of 5 tasks
1/5: running
2/5: running
3/5: running
4/5: running
5/5: running
verify: Service converged
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$ docker stack services wikistack
ID                  NAME                MODE                REPLICAS            IMAGE PORTS
mv28b44lmtdb        wikistack_api       replicated          5/5                 wikicrawler-api:step5-python *:5000->5000/tcp
owuatcqmyg61        wikistack_redis     replicated          1/1                 redis:latest
wkcx725u4q2d        wikistack_web       replicated          1/1                 wikicrawler-web:step5-python *:80->80/tcp
[node1] (local) root@192.168.0.7 ~/zahier24963lab3test1/test
$




-------------------------------------
SECOND TERMINAL
-------------------------------------
###############################################################
#                          WARNING!!!!                        #
# This is a sandbox environment. Using personal credentials   #
# is HIGHLY! discouraged. Any consequences of doing so are    #
# completely the user's responsibilites.                      #
#                                                             #
# The PWD team.                                               #
###############################################################
[node2] (local) root@192.168.0.8 ~
$ docker swarm join --token SWMTKN-1-2lqadnxkgaohkqf8r4ezh78ym1fnmrm257h9flq5x57rwfdzsd-2ob6b33lmkws1eo4om2jrxbsu 192.168.0.7:2377
This node joined a swarm as a worker.
[node2] (local) root@192.168.0.8 ~
$

